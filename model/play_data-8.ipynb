{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from mrnn7 import MilliesDataset, MilliesRNN\n",
    "from math import ceil\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "from hessianfree import HessianFree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardcore_loss(output, target, model_params):\n",
    "    firing_reg = 1e-1\n",
    "    weight_reg = 1e-5\n",
    "    weight_sum = torch.zeros((1))\n",
    "    for name, param in model_params: \n",
    "        if \"weight\" in name:\n",
    "            weight_sum += torch.sum(param **  2)\n",
    "\n",
    "    loss = torch.sum((output - target)**2) + firing_reg * torch.sum(output ** 2) + weight_reg * weight_sum\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "muscle_length_vec = torch.tensor([9.8, 10.8, 13.7, 6.8, 7.6, 8.7, 7.4, 16.2, 14.4, 13.8, 13.8, 25.4, 23.2, 27.9, 9.3, 13.4, 11.4, 11.4, 2.7, 3.3, 11.6, 13.2, 8.6, 17.3, 8.1, 5.9, 6.2, 6.3, 5.1, 6.4, 4.9, 2.8, 5.2, 7.4, 7.5, 8.4, 7.5, 8.0, 8.4, 7.5, 6.5, 6.3, 7.2, 7.0, 6.8, 5.9, 5.4, 6.8, 5.5, 7.1])\n",
    "muscle_weight_vec = (1/muscle_length_vec) * (2.5*torch.min(muscle_length_vec))\n",
    "\n",
    "def hardcore_loss_weighted(output, target, model_params):\n",
    "    firing_reg = 1e-1\n",
    "    weight_reg = 1e-5\n",
    "    weight_sum = torch.zeros((1))\n",
    "    for name, param in model_params: \n",
    "        if \"weight\" in name:\n",
    "            weight_sum += torch.sum(param **  2)\n",
    "    \n",
    "    target_diff_sum = torch.sum((muscle_weight_vec*(output - target))**2)\n",
    "\n",
    "    loss = target_diff_sum + firing_reg * torch.sum(output ** 2) + weight_reg * weight_sum\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "whole_dataset = MilliesDataset('monkey_data.mat')\n",
    "dataset_size = len(whole_dataset)\n",
    "train_dataset, test_dataset = random_split(whole_dataset, [401, 101])\n",
    "\n",
    "in_dim, out_dim, trial_len = whole_dataset.dimensions() #  21  &  50\n",
    "hid_dim = 100\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=ceil(len(train_dataset)/5), shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "\n",
    "# for generating output later\n",
    "whole_dataloader = DataLoader(whole_dataset, batch_size = len(whole_dataset), shuffle=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Batch [1], Loss: 0.0232\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep(closure, M_inv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# gradient descent\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     64\u001b[0m loss_error\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/anaconda3/envs/cap/lib/python3.12/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cap/lib/python3.12/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training pipeline\n",
    "\n",
    "\n",
    "learning_rate = 0.0005\n",
    "hessian = False\n",
    "hardcore = False\n",
    "intermodule_connections_removed = .9\n",
    "\n",
    "num_epochs = 50\n",
    "training_loss = []\n",
    "\n",
    "\n",
    "model = MilliesRNN(in_dim, hid_dim, out_dim, True)\n",
    "module1 = model.h2o\n",
    "prune.random_unstructured(module1, name=\"weight\", amount=intermodule_connections_removed)\n",
    "module2 = model.thal\n",
    "prune.random_unstructured(module2, name=\"weight\", amount=intermodule_connections_removed)\n",
    "\n",
    "\n",
    "if hardcore:\n",
    "    criterion1 = hardcore_loss\n",
    "    # criterion2 = hardcore_loss_weighted\n",
    "else:\n",
    "    criterion1 = nn.MSELoss() \n",
    "\n",
    "if hessian:\n",
    "    optimizer = HessianFree(model.parameters(), use_gnm=True, verbose=True)\n",
    "else:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (inp_batch, out_batch) in enumerate(train_dataloader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inp_batch)   \n",
    "\n",
    "        if hardcore:\n",
    "            loss = criterion1(outputs, out_batch, model.named_parameters())\n",
    "        else:\n",
    "            loss = criterion1(outputs, out_batch)\n",
    "\n",
    "        def closure():\n",
    "            gen_output = model(inp_batch)\n",
    "            loss = criterion1(gen_output, out_batch, model.named_parameters())\n",
    "            loss.backward(create_graph=True)\n",
    "            return loss, gen_output\n",
    "        \n",
    "        if hessian:\n",
    "            optimizer.step(closure, M_inv=None)\n",
    "        else: # gradient descent\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        training_loss.append(loss.item())\n",
    "        print(\n",
    "            f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "            f\"Batch [{i + 1}], \"\n",
    "            f\"Loss: {loss.item():.4f}\"\n",
    "        )\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training loss \n",
    "plt.plot(loss_error)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test loss (mse): 0.00022657870431430638\n"
     ]
    }
   ],
   "source": [
    "# gets test loss using both criterion\n",
    "\n",
    "num_correct = 0\n",
    "num_samples = len(test_dataset)\n",
    "\n",
    "model.eval()\n",
    "loss = 0\n",
    "with torch.no_grad():\n",
    "    inp, out_true = next(iter(test_dataloader))\n",
    "    out = model(inp)\n",
    "    loss1 = criterion1(out, out_true)\n",
    "\n",
    "print(f\"Average test loss (mse): {loss1 / num_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with torch.no_grad():\n",
    "    inp, out_true = next(iter(whole_dataloader))\n",
    "    out = model(inp)\n",
    "\n",
    "with open('model_outputs/using_dataloader_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(out, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newallensdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
