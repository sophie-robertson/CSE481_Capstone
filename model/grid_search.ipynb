{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from math import ceil\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_default_device('cuda')\n",
    "from mrnn7 import MilliesDataset, MilliesRNN\n",
    "from hessianfree import HessianFree\n",
    "\n",
    "\n",
    "\n",
    "# Load data\n",
    "whole_dataset = MilliesDataset('monkey_data.mat')\n",
    "dataset_size = len(whole_dataset)\n",
    "train_dataset, test_dataset = random_split(whole_dataset, [401, 101])\n",
    "\n",
    "in_dim, out_dim, trial_len = whole_dataset.dimensions() #  21  &  50\n",
    "hid_dim = 100\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=ceil(len(train_dataset)/5), shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "\n",
    "# for generating output later\n",
    "whole_dataloader = DataLoader(whole_dataset, batch_size = len(whole_dataset), shuffle=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When i = 0, clipping, when i = 1, no clipping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching over models...:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 0.01, batch size = 0.3333333333333333, i = 0, weight decay = 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching over models...:   0%|          | 0/3 [05:46<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     58\u001b[0m     inp, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(test_dataset))\n\u001b[0;32m---> 59\u001b[0m     gen_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     loss1 \u001b[38;5;241m=\u001b[39m criterion1(gen_out, out)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss1\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cap/lib/python3.12/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cap/lib/python3.12/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/UW/CSE481/CSE481_Capstone/model/mrnn7.py:49\u001b[0m, in \u001b[0;36mMilliesRNN.forward\u001b[0;34m(self, data, dopamine)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, dopamine \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m): \n\u001b[1;32m     43\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    x --> N x L\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    hidden state --> N x H\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    output --> N x O\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     50\u001b[0m     holds \u001b[38;5;241m=\u001b[39m data[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     51\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import pickle \n",
    "from tqdm import tqdm\n",
    "\n",
    "from mrnn7 import MilliesRNN\n",
    "from hessianfree import HessianFree\n",
    "\n",
    "hessian = False\n",
    "hardcore = True\n",
    "intermodule_connections_removed = .9\n",
    "\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_size = [3,4,5]\n",
    "weight_decay = [0,1e-6,1e-5,1e-4]\n",
    "\n",
    "num_epochs = 20\n",
    "test_losses = {}\n",
    "\n",
    "print(\"When i = 0, clipping, when i = 1, no clipping\\n\")\n",
    "\n",
    "criterion1 = nn.MSELoss() \n",
    "\n",
    "for l in tqdm(learning_rates, desc=\"Searching over models...\"):\n",
    "    for b in batch_size:\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=ceil(len(train_dataset)/b), shuffle=True)\n",
    "        for w in weight_decay:\n",
    "            for i in range(2):\n",
    "                print(\"Learning rate = \" + str(l) + \", batch size = \" + str(1/b) + \", i = \" + str(i) + \", weight decay = \" + str(w) + \"\\n\")\n",
    "                model_type = f\"mse_{l}_{b}_{i}_{w}\"\n",
    "                model = MilliesRNN(in_dim, hid_dim, out_dim, True)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=l, weight_decay = w)\n",
    "                module1 = model.h2o\n",
    "                prune.random_unstructured(module1, name=\"weight\", amount=intermodule_connections_removed)\n",
    "                module2 = model.thal\n",
    "                prune.random_unstructured(module2, name=\"weight\", amount=intermodule_connections_removed)\n",
    "                model.train()\n",
    "                for epoch in range(num_epochs):\n",
    "                    for i, (inp_batch, out_batch) in enumerate(train_dataloader):\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        outputs = model(inp_batch)   \n",
    "\n",
    "                        loss = criterion1(outputs, out_batch)\n",
    "                        \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if(i == 0):\n",
    "                            nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "                \n",
    "\n",
    "                num_samples = len(test_dataset)\n",
    "            \n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    inp, out = next(iter(test_dataset))\n",
    "                    gen_out = model(inp)\n",
    "                    loss1 = criterion1(gen_out, out)\n",
    "\n",
    "                print(f\"Average test: {loss1 / num_samples}\\n\")\n",
    "                test_losses[model_type] = loss1 / num_samples\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    inp, out_true = next(iter(whole_dataloader))\n",
    "                    whole_out = model(inp)\n",
    "\n",
    "                with open(f'outputs/{model_type}.pickle', 'wb') as handle:\n",
    "                    pickle.dump(whole_out, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse_0.01_3_0_0': {tensor(0.0002)}, 'mse_0.01_3_1_0': {tensor(0.0002)}, 'mse_0.01_3_0_1e-06': {tensor(0.0002)}, 'mse_0.01_3_1_1e-06': {tensor(0.0002)}, 'mse_0.01_3_0_1e-05': {tensor(0.0002)}, 'mse_0.01_3_1_1e-05': {tensor(0.0002)}, 'mse_0.01_3_0_0.0001': {tensor(0.0002)}, 'mse_0.01_3_1_0.0001': {tensor(0.0002)}, 'mse_0.01_4_0_0': {tensor(0.0002)}, 'mse_0.01_4_1_0': {tensor(0.0002)}, 'mse_0.01_4_0_1e-06': {tensor(0.0002)}, 'mse_0.01_4_1_1e-06': {tensor(0.0002)}, 'mse_0.01_4_0_1e-05': {tensor(0.0002)}, 'mse_0.01_4_1_1e-05': {tensor(0.0002)}, 'mse_0.01_4_0_0.0001': {tensor(0.0002)}, 'mse_0.01_4_1_0.0001': {tensor(0.0002)}, 'mse_0.01_5_0_0': {tensor(0.0002)}, 'mse_0.01_5_1_0': {tensor(0.0002)}, 'mse_0.01_5_0_1e-06': {tensor(0.0002)}, 'mse_0.01_5_1_1e-06': {tensor(0.0002)}, 'mse_0.01_5_0_1e-05': {tensor(0.0002)}, 'mse_0.01_5_1_1e-05': {tensor(0.0002)}, 'mse_0.01_5_0_0.0001': {tensor(0.0002)}, 'mse_0.01_5_1_0.0001': {tensor(0.0002)}, 'mse_0.001_3_0_0': {tensor(0.0002)}, 'mse_0.001_3_1_0': {tensor(0.0002)}, 'mse_0.001_3_0_1e-06': {tensor(0.0002)}, 'mse_0.001_3_1_1e-06': {tensor(0.0002)}, 'mse_0.001_3_0_1e-05': {tensor(0.0002)}, 'mse_0.001_3_1_1e-05': {tensor(0.0002)}, 'mse_0.001_3_0_0.0001': {tensor(0.0002)}, 'mse_0.001_3_1_0.0001': {tensor(0.0002)}, 'mse_0.001_4_0_0': {tensor(0.0002)}, 'mse_0.001_4_1_0': {tensor(0.0002)}, 'mse_0.001_4_0_1e-06': {tensor(0.0002)}, 'mse_0.001_4_1_1e-06': {tensor(0.0002)}, 'mse_0.001_4_0_1e-05': {tensor(0.0002)}, 'mse_0.001_4_1_1e-05': {tensor(0.0002)}, 'mse_0.001_4_0_0.0001': {tensor(0.0002)}, 'mse_0.001_4_1_0.0001': {tensor(0.0002)}, 'mse_0.001_5_0_0': {tensor(0.0002)}, 'mse_0.001_5_1_0': {tensor(0.0002)}, 'mse_0.001_5_0_1e-06': {tensor(0.0002)}, 'mse_0.001_5_1_1e-06': {tensor(0.0002)}, 'mse_0.001_5_0_1e-05': {tensor(0.0002)}, 'mse_0.001_5_1_1e-05': {tensor(0.0002)}, 'mse_0.001_5_0_0.0001': {tensor(0.0002)}, 'mse_0.001_5_1_0.0001': {tensor(0.0002)}, 'mse_0.0001_3_0_0': {tensor(0.0002)}, 'mse_0.0001_3_1_0': {tensor(0.0002)}, 'mse_0.0001_3_0_1e-06': {tensor(0.0002)}, 'mse_0.0001_3_1_1e-06': {tensor(0.0002)}, 'mse_0.0001_3_0_1e-05': {tensor(0.0002)}, 'mse_0.0001_3_1_1e-05': {tensor(0.0002)}, 'mse_0.0001_3_0_0.0001': {tensor(0.0002)}, 'mse_0.0001_3_1_0.0001': {tensor(0.0002)}, 'mse_0.0001_4_0_0': {tensor(0.0002)}, 'mse_0.0001_4_1_0': {tensor(0.0002)}, 'mse_0.0001_4_0_1e-06': {tensor(0.0002)}, 'mse_0.0001_4_1_1e-06': {tensor(0.0002)}, 'mse_0.0001_4_0_1e-05': {tensor(0.0002)}, 'mse_0.0001_4_1_1e-05': {tensor(0.0002)}, 'mse_0.0001_4_0_0.0001': {tensor(0.0002)}, 'mse_0.0001_4_1_0.0001': {tensor(0.0002)}, 'mse_0.0001_5_0_0': {tensor(0.0002)}, 'mse_0.0001_5_1_0': {tensor(0.0002)}, 'mse_0.0001_5_0_1e-06': {tensor(0.0002)}, 'mse_0.0001_5_1_1e-06': {tensor(0.0002)}, 'mse_0.0001_5_0_1e-05': {tensor(0.0002)}, 'mse_0.0001_5_1_1e-05': {tensor(0.0002)}, 'mse_0.0001_5_0_0.0001': {tensor(0.0002)}, 'mse_0.0001_5_1_0.0001': {tensor(0.0002)}}\n"
     ]
    }
   ],
   "source": [
    "print(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'outputs/test_loss_mse.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_losses, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{tensor(0.0002)}\n",
      "{tensor(0.0002)}\n"
     ]
    }
   ],
   "source": [
    "print(max(test_losses.values()))\n",
    "print(min(test_losses.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
