{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341.0\n",
      "(502, 341, 21)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "monkey_data = loadmat('monkey_data.mat') \n",
    "visual_data = monkey_data['inp'][0]\n",
    "muscle_data = monkey_data['targ'][0]\n",
    "test = np.zeros((502, 2))\n",
    "for i, data in enumerate(visual_data):\n",
    "    test[i] = data.shape\n",
    "\n",
    "print(test[:,1].max())\n",
    "batch_size = visual_data.shape[0] # N, 502\n",
    "trial_len = int(test[:,1].max()) # visual_data[0].shape[1] # T, 298 \n",
    "in_dim = visual_data[0].shape[0] # L, 21\n",
    "out_dim = muscle_data[0].shape[0] # O, 50\n",
    "\n",
    "hid_dim = 100\n",
    "num_layers = 3\n",
    "new_visual_data = np.zeros((batch_size, trial_len, in_dim))\n",
    "\n",
    "for i, data in enumerate(visual_data):\n",
    "    new_visual_data[i, 0:visual_data[i].shape[1], :] = visual_data[i].transpose()\n",
    "print(new_visual_data.shape)\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import gen_batches\n",
    "# np.random.seed()\n",
    "\n",
    " # shuffling was somehow change \n",
    "train_idx, test_idx = train_test_split(\n",
    "     range(batch_size), \n",
    "     test_size=0.2, \n",
    "     shuffle=True )\n",
    "\n",
    "train_input = np.zeros((int(batch_size * .8), trial_len, in_dim))\n",
    "train_output = np.zeros((int(batch_size * .8), trial_len, out_dim))\n",
    "test_input = np.zeros((int(np.ceil(batch_size * .2)), trial_len, in_dim))\n",
    "test_output = np.zeros((int(np.ceil(batch_size * .2)), trial_len, out_dim))\n",
    "train_ind = 0\n",
    "test_ind = 0\n",
    "for i, data in enumerate(visual_data):\n",
    "     if i in train_idx:\n",
    "       # train_input[train_ind, 0:visual_data[i].shape[1], :] = visual_data[i].transpose()\n",
    "       train_input[train_ind, -visual_data[i].shape[1]:, :] = visual_data[i].transpose()\n",
    "       train_output[train_ind, -visual_data[i].shape[1]:, :] = muscle_data[i].transpose()\n",
    "       train_ind += 1\n",
    "     else:\n",
    "        test_input[test_ind, -visual_data[i].shape[1]:, :] = visual_data[i].transpose()\n",
    "        test_output[test_ind, -visual_data[i].shape[1]:, :] = muscle_data[i].transpose()\n",
    "        test_ind += 1\n",
    "\n",
    "# for use in weighted loss\n",
    "muscle_length_vec = torch.tensor([9.8, 10.8, 13.7, 6.8, 7.6, 8.7, 7.4, 16.2, 14.4, 13.8, 13.8, 25.4, 23.2, 27.9, 9.3, 13.4, 11.4, 11.4, 2.7, 3.3, 11.6, 13.2, 8.6, 17.3, 8.1, 5.9, 6.2, 6.3, 5.1, 6.4, 4.9, 2.8, 5.2, 7.4, 7.5, 8.4, 7.5, 8.0, 8.4, 7.5, 6.5, 6.3, 7.2, 7.0, 6.8, 5.9, 5.4, 6.8, 5.5, 7.1])\n",
    "muscle_weight_vec = (1/muscle_length_vec) * (2.5*torch.min(muscle_length_vec))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When i = 0, clipping, when i = 1, no clipping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching over models...:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 0.01, batch size = 0.3333333333333333, i = 0 weight decay = 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching over models...:   0%|          | 0/3 [01:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "empty(): argument 'size' (position 1) must be tuple of ints, but found element of type float at pos 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m(i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     59\u001b[0m             nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m num_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     64\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_input)\n",
      "\u001b[0;31mTypeError\u001b[0m: empty(): argument 'size' (position 1) must be tuple of ints, but found element of type float at pos 0"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import pickle \n",
    "from tqdm import tqdm\n",
    "\n",
    "from mrnn7 import MilliesRNN\n",
    "from hessianfree import HessianFree\n",
    "\n",
    "hessian = False\n",
    "hardcore = True\n",
    "intermodule_connections_removed = .9\n",
    "\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_size = [3,4,5]\n",
    "weight_decay = [0,1e-6,1e-5,1e-4]\n",
    "\n",
    "num_epochs = 5\n",
    "test_losses = {}\n",
    "\n",
    "print(\"When i = 0, clipping, when i = 1, no clipping\\n\")\n",
    "\n",
    "criterion1 = nn.MSELoss() \n",
    "\n",
    "for l in tqdm(learning_rates, desc=\"Searching over models...\"):\n",
    "    for b in batch_size:\n",
    "        for w in weight_decay:\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=l, weight_decay = w)\n",
    "            for i in range(2):\n",
    "                print(\"Learning rate = \" + str(l) + \", batch size = \" + str(1/b) + \", i = \" + str(i) + \" weight decay = \" + str(w) + \"\\n\")\n",
    "                model_type = f\"mse_{l}_{b}_{i}_{w}\"\n",
    "                model = MilliesRNN(in_dim, hid_dim, out_dim, True)\n",
    "                module1 = model.h2o\n",
    "                prune.random_unstructured(module1, name=\"weight\", amount=intermodule_connections_removed)\n",
    "                module2 = model.thal\n",
    "                prune.random_unstructured(module2, name=\"weight\", amount=intermodule_connections_removed)\n",
    "                model.train()\n",
    "                for epoch in range(num_epochs):\n",
    "                    batches = []\n",
    "                    shuffed = np.arange(0,401)\n",
    "                    np.random.shuffle(shuffed)\n",
    "                    for i in range(b):\n",
    "                        curr_b_size = int(train_input.shape[0]/b)\n",
    "                        idx = shuffed[(curr_b_size*i):curr_b_size*(i+1)]\n",
    "                        \n",
    "                        batches.append(idx)\n",
    "                    \n",
    "                    for j, batch in enumerate(batches):\n",
    "                        \n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        outputs = model(torch.from_numpy(train_input[batch]).to(torch.float32))   \n",
    "\n",
    "                        loss = criterion1(outputs, torch.from_numpy(train_output[batch]).to(torch.float32))\n",
    "                        \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if(i == 0):\n",
    "                            nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "                \n",
    "                preds = torch.empty((curr_b_size, trial_len, out_dim))\n",
    "\n",
    "                num_correct = 0\n",
    "                num_samples = len(test_input)\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    out = model(torch.from_numpy(test_input).to(torch.float32))\n",
    "                    loss1 = criterion1(out, torch.from_numpy(test_output).to(torch.float32), model.named_parameters())\n",
    "\n",
    "                print(f\"Average test: {loss1 / num_samples}\\n\")\n",
    "                test_losses[model_type] = {loss1 / num_samples}\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    out = model(torch.from_numpy(new_visual_data).to(torch.float32))\n",
    "\n",
    "                with open(f'outputs/{model_type}.pickle', 'wb') as handle:\n",
    "                    pickle.dump(out, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
